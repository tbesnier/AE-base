{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A3000 Laptop GPU'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import mesh_sampling\n",
    "import trimesh\n",
    "from shape_data import ShapeData\n",
    "from SimplePointNet import SimplePointNet, PointNetAutoEncoder, Decoder, Encoder, SimpleTransformer\n",
    "\n",
    "from autoencoder_dataset import autoencoder_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spiral_utils import get_adj_trigs, generate_spirals\n",
    "from models import SpiralAutoencoder\n",
    "from train_funcs import train_autoencoder_dataloader\n",
    "from test_funcs import test_autoencoder_dataloader\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "meshpackage = 'trimesh' # 'mpi-mesh', 'trimesh'\n",
    "root_dir = '../Data'\n",
    "\n",
    "dataset = 'COMA'\n",
    "name = ''\n",
    "\n",
    "GPU = True\n",
    "device_idx = 0\n",
    "torch.cuda.get_device_name(device_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T = np.load(os.path.join(root_dir, dataset, 'preprocessed_identity_pointnet_original', \"train.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = np.dstack([T[0]]*19282).swapaxes(0,2).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a = np.dstack([T[0]]*19282).swapaxes(0,2).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(os.path.join(root_dir, dataset, 'preprocessed_identity_pointnet_original', \"train.npy\"), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B = np.load(os.path.join(root_dir, dataset, 'preprocessed_identity_pointnet_original', \"points_train\" ,\"0.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "generative_model = 'autoencoder'\n",
    "downsample_method = 'COMA_downsample' # choose'COMA_downsample' or 'meshlab_downsample'\n",
    "\n",
    "# below are the arguments for the DFAUST run\n",
    "reference_mesh_file = os.path.join(root_dir, dataset, 'template', 'template.obj')\n",
    "downsample_directory = os.path.join(root_dir, dataset,'template', downsample_method)\n",
    "ds_factors = [4, 4, 4, 4]\n",
    "step_sizes = [2, 2, 1, 1, 1]\n",
    "filter_sizes_enc = [[64, 128], 64, [128, 64, 64]]\n",
    "filter_sizes_dec = [128]\n",
    "dilation_flag = True\n",
    "if dilation_flag:\n",
    "    dilation=[2, 2, 1, 1, 1] \n",
    "else:\n",
    "    dilation = None\n",
    "reference_points = [[3567,4051,4597]] #[[414]]  # [[3567,4051,4597]] used for COMA with 3 disconnected components\n",
    "\n",
    "args = {'generative_model': generative_model,\n",
    "        'name': name, 'data': os.path.join(root_dir, dataset, 'preprocessed_identity_pointnet_original',name),\n",
    "        'results_folder':  os.path.join(root_dir, dataset,'results_identity/pointnet_original_'+ generative_model),\n",
    "        'reference_mesh_file':reference_mesh_file, 'downsample_directory': downsample_directory,\n",
    "        'checkpoint_file': 'checkpoint',\n",
    "        'seed':2, 'loss':'varifold',\n",
    "        'batch_size':16, 'num_epochs':30, 'eval_frequency':200, 'num_workers': 4,\n",
    "        'filter_sizes_enc': filter_sizes_enc, 'filter_sizes_dec': filter_sizes_dec,\n",
    "        'nz':128, \n",
    "        'ds_factors': ds_factors, 'step_sizes' : step_sizes, 'dilation': dilation,\n",
    "        'lr':1e-3, \n",
    "        'regularization': 5e-5,\n",
    "        'scheduler': True, 'decay_rate': 0.99,'decay_steps':1,  \n",
    "        'resume': True,\n",
    "        \n",
    "        'mode':'test', 'shuffle': True, 'nVal': 100, 'normalization': True}\n",
    "\n",
    "args['results_folder'] = os.path.join(args['results_folder'],'latent_'+str(args['nz']))\n",
    "    \n",
    "if not os.path.exists(os.path.join(args['results_folder'])):\n",
    "    os.makedirs(os.path.join(args['results_folder']))\n",
    "\n",
    "summary_path = os.path.join(args['results_folder'],'summaries',args['name'])\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)  \n",
    "    \n",
    "checkpoint_path = os.path.join(args['results_folder'],'checkpoints', args['name'])\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "samples_path = os.path.join(args['results_folder'],'samples', args['name'])\n",
    "if not os.path.exists(samples_path):\n",
    "    os.makedirs(samples_path)\n",
    "    \n",
    "prediction_path = os.path.join(args['results_folder'],'predictions', args['name'])\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.makedirs(prediction_path)\n",
    "\n",
    "if not os.path.exists(downsample_directory):\n",
    "    os.makedirs(downsample_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data .. \n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args['seed'])\n",
    "print(\"Loading data .. \")\n",
    "if not os.path.exists(args['data']+'/mean.npy') or not os.path.exists(args['data']+'/std.npy'):\n",
    "    shapedata =  ShapeData(nVal=args['nVal'], \n",
    "                          train_file=args['data']+'/train.npy', \n",
    "                          test_file=args['data']+'/test.npy', \n",
    "                          reference_mesh_file=args['reference_mesh_file'],\n",
    "                          normalization = args['normalization'],\n",
    "                          meshpackage = meshpackage, load_flag = True, mean_subtraction_only = False)\n",
    "    np.save(args['data']+'/mean.npy', shapedata.mean)\n",
    "    np.save(args['data']+'/std.npy', shapedata.std)\n",
    "else:\n",
    "    shapedata = ShapeData(nVal=args['nVal'], \n",
    "                         train_file=args['data']+'/train.npy',\n",
    "                         test_file=args['data']+'/test.npy', \n",
    "                         reference_mesh_file=args['reference_mesh_file'],\n",
    "                         normalization = args['normalization'],\n",
    "                         meshpackage = meshpackage, load_flag = False, mean_subtraction_only = False)\n",
    "    shapedata.mean = np.load(args['data']+'/mean.npy')\n",
    "    shapedata.std = np.load(args['data']+'/std.npy')\n",
    "    shapedata.n_vertex = shapedata.mean.shape[0]\n",
    "    shapedata.n_features = shapedata.mean.shape[1]\n",
    "    \n",
    "print(\"... Done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# Building model, optimizer, and loss function\n",
    "\n",
    "dataset_train = autoencoder_dataset(root_dir = args['data'], points_dataset = 'train',\n",
    "                                           shapedata = shapedata,\n",
    "                                           normalization = args['normalization'])\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = args['shuffle'], num_workers = args['num_workers'])\n",
    "\n",
    "dataset_val = autoencoder_dataset(root_dir = args['data'], points_dataset = 'val', \n",
    "                                         shapedata = shapedata,\n",
    "                                         normalization = args['normalization'])\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = False, num_workers = args['num_workers'])\n",
    "\n",
    "dataset_test = autoencoder_dataset(root_dir = args['data'], points_dataset = 'test',\n",
    "                                          shapedata = shapedata,\n",
    "                                          normalization = args['normalization'])\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = False, num_workers = args['num_workers'])\n",
    "\n",
    "\n",
    "if 'autoencoder' in args['generative_model']:\n",
    "        model = PointNetAutoEncoder(latent_size=args['nz'],\n",
    "                                    filter_enc = args['filter_sizes_enc'], \n",
    "                                    filter_dec = args['filter_sizes_dec'],  \n",
    "                                    num_points=shapedata.n_vertex+1, \n",
    "                                    device=device).to(device)                  \n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(),lr=args['lr'],weight_decay=args['regularization'])\n",
    "if args['scheduler']:\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optim, args['decay_steps'],gamma=args['decay_rate'])\n",
    "else:\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mesh = trimesh.load(\"../Data/COMA/template/template.obj\")\n",
    "faces = torch.Tensor(template_mesh.faces)\n",
    "mesh1 = trimesh.load_mesh(\"../datasets/COMA/FaceTalk_170725_00137_TA/bareteeth/bareteeth.000001.ply\")\n",
    "mesh2 = trimesh.load_mesh(\"../datasets/COMA/FaceTalk_170728_03272_TA/bareteeth/bareteeth.000001.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchdtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "def computeNormalsCenters(vertices, faces):\n",
    "    \"\"\"\n",
    "    Function that computes centers and surface elements (area * normal) of triangles of a mesh\n",
    "    :np.array, Nvx3 vertices: vertices of the mesh\n",
    "    :np.array, NFx3 faces: faces of the mesh\n",
    "    :return np.array, NFx3 centers np.array , NFx3 surfel: centers and surface elements of the mesh\n",
    "    \"\"\"\n",
    "    xDef1 = torch.Tensor(vertices[faces[:, 0], :])\n",
    "    xDef2 = torch.Tensor(vertices[faces[:, 1], :])\n",
    "    xDef3 = torch.Tensor(vertices[faces[:, 2], :])\n",
    "    \n",
    "    centers, normals = (xDef1 + xDef2 + xDef3) / 3, 0.5 * torch.cross(xDef2 - xDef1, xDef3 - xDef1)\n",
    "    areas = (normals ** 2).sum(dim=1)[:, None].sqrt()\n",
    "    \n",
    "    return centers, normals, np.squeeze(areas)\n",
    "\n",
    "def lazy_varifold_dist_batch(areas1, normals1, centers1, areas2, normals2, centers2, sigma):\n",
    "    \"\"\"\n",
    "    Pykeops function to compute absolute varifolds product over 2 batches of meshes (center + surface elements)\n",
    "    :np.array, N_1x3 surfels1: surfels of batch number 1\n",
    "    :np.array, N_1x3 centers1: centers of batch number 1\n",
    "    :np.array, N_2x3 surfels2: surfels of batch number 2\n",
    "    :np.array, N_2x3 centers2: centers of batch number 2\n",
    "    :float sigma: sigma parameter of gaussian kernel\n",
    "    :return np.array N_1xN_2 batch of absolute products:\n",
    "    \"\"\"\n",
    "    # Current, and absolute varifolds can be defined directly from surface elements (normals * areas)\n",
    "    surfels1 = areas1[:, :, None]*normals1\n",
    "    surfels2 = areas2[:, :, None]*normals2\n",
    "    # Transforming into Pykeops lazytensors (no direct evaluation, compute during compilation)\n",
    "    surfe_laz_1 = LazyTensor(surfels1[:, None, :, None, :].contiguous().to(device))\n",
    "    center_laz_1 = LazyTensor(centers1[:, None, :, None, :].contiguous().to(device))\n",
    "    surfe_laz_2 = LazyTensor(surfels2[None, :, None, :, :].contiguous().to(device))\n",
    "    center_laz_2 = LazyTensor(centers2[None, :, None, :, :].contiguous().to(device))\n",
    "    # Computing absolute varifolds product\n",
    "    gamma = 1 / (sigma * sigma)\n",
    "    D2 = ((center_laz_1 - center_laz_2) ** 2).sum()\n",
    "    K = (-D2 * gamma).exp() * (surfe_laz_1 * surfe_laz_2).sum().abs()\n",
    "    final_K = K.sum_reduction(dim=3)\n",
    "    return final_K.sum(dim=[2,3])\n",
    "\n",
    "def lazy_varifold_or_dist_batch(areas1, normals1, centers1, areas2, normals2, centers2, sigma):\n",
    "    \"\"\"\n",
    "    Pykeops function to compute oriented varifolds product over 2 batches of meshes (center + surface elements)\n",
    "    :np.array, N_1x3 surfels1: surfels of batch number 1\n",
    "    :np.array, N_1x3 centers1: centers of batch number 1\n",
    "    :np.array, N_2x3 surfels2: surfels of batch number 2\n",
    "    :np.array, N_2x3 centers2: centers of batch number 2\n",
    "    :float sigma: sigma parameter of gaussian kernel\n",
    "    :return np.array N_1xN_2 batch of oriented varifolds products:\n",
    "    \"\"\"\n",
    "    # Transforming into Pykeops lazytensors (no direct evaluation, compute during compilation)\n",
    "    area_laz_1 = LazyTensor(areas1[:, None, :, None, None].contiguous().to(device))\n",
    "    norm_laz_1 = LazyTensor(normals1[:, None, :, None, :].contiguous().to(device))\n",
    "    center_laz_1 = LazyTensor(centers1[:, None, :, None, :].contiguous().to(device))\n",
    "    area_laz_2 = LazyTensor(areas2[None, :, None, :, None].contiguous().to(device))\n",
    "    norm_laz_2 = LazyTensor(normals2[None, :, None, :, :].contiguous().to(device))\n",
    "    center_laz_2 = LazyTensor(centers2[None, :, None, :, :].contiguous().to(device))\n",
    "    # Computing oriented varifolds product\n",
    "    gamma = 1 / (sigma * sigma)\n",
    "    D2 = ((center_laz_1 - center_laz_2) ** 2).sum()\n",
    "    K = (-D2 * gamma).exp() * ((norm_laz_1 * norm_laz_2).sum()/0.5).exp() * (area_laz_1* area_laz_2).sum()\n",
    "    final_K = K.sum_reduction(dim=3)\n",
    "    return final_K.sum(dim=[2,3])\n",
    "\n",
    "def compute_feats(vertices, faces, do_cm=False):\n",
    "    \"\"\"\n",
    "    Computing centers and surface element of a mesh, converting them to Pytorch tensors. Centroid normalization if needed\n",
    "    :np.array Nvx3 vertices: vertices of the mesh\n",
    "    :np.array Nfx3 faces: faces of the mesh\n",
    "    :bool do_cm: centroid normalization or not\n",
    "    :return (torch.Tensor, Nfx3), (torch.Tensor, Nfx3), (np.array, 3): centers tensor, surfel tensor, centroid (None if not needed)\n",
    "    \"\"\"\n",
    "    centers, normals, areas = computeNormalsCenters(vertices, faces)\n",
    "    cm = None\n",
    "    if do_cm:\n",
    "        cm = np.average(centers, weights=areas, axis=0)\n",
    "        centers = centers-cm\n",
    "    return centers.float(), normals.float(), areas.float(), cm\n",
    "\n",
    "\n",
    "def prepare_batch(vertices_list, faces_list, centroid=False):\n",
    "    \"\"\"\n",
    "    Computing batched centers and surface element of a list of meshes, converting them to Pytorch tensors. Centroid normalization if needed\n",
    "    :np.array NbxNvx3 vertices: Batched vertices of the meshes\n",
    "    :np.array NbxNfx3 faces: Batched faces of the meshes\n",
    "    :bool do_cm: centroid normalization or not\n",
    "    :return (torch.Tensor, NbxNfx3), (torch.Tensor, NbxNfx3), (np.array, Nbx3): batched centers tensor, surfel tensor, centroid (None if not needed)\n",
    "    \"\"\"\n",
    "    Ns = [f.shape[0] for f in faces_list]\n",
    "    N = max(Ns)\n",
    "    batch_areas = torch.zeros((len(faces_list), N))\n",
    "    batch_normals = torch.zeros((len(faces_list), N, 3))\n",
    "    batch_centers = torch.zeros((len(faces_list), N, 3))\n",
    "    centroids = []\n",
    "    for i in range(len(faces_list)):\n",
    "        N_i = faces_list[i].shape[0]\n",
    "        batch_centers[i, :N_i, :], batch_normals[i, :N_i, :], batch_areas[i, :N_i], cm = compute_feats(vertices_list[i], faces_list[i], centroid)\n",
    "        centroids.append(cm)\n",
    "    if not centroid:\n",
    "        centroids = None\n",
    "    return batch_areas, batch_normals, batch_centers, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#F1, V1 = torch.Tensor(template_mesh.faces).to(dtype=torch.int32, device='cpu'), torch.Tensor(template_mesh.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c1, n1, a1, _ = compute_feats(template_mesh.vertices, template_mesh.faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faces_list1 = torch.Tensor(mesh1.faces).to(dtype=torch.int32, device='cpu').repeat(args['batch_size'],1,1).numpy()\n",
    "vertices_list1 = torch.Tensor(mesh1.vertices).repeat(args['batch_size'],1,1).numpy()\n",
    "\n",
    "faces_list2 = torch.Tensor(mesh2.faces).to(dtype=torch.int32, device='cpu').repeat(args['batch_size'],1,1).numpy()\n",
    "vertices_list2 = torch.Tensor(mesh2.vertices).repeat(args['batch_size'],1,1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a1, n1, c1, _  = prepare_batch(vertices_list1, faces_list1)\n",
    "a2, n2, c2, _  = prepare_batch(vertices_list2, faces_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_areas, batch_normals, batch_centers, centroids = prepare_batch(vertices_list, faces_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mu1 = lazy_varifold_or_dist_batch(a1, n1, c1, a1, n1, c1, sigma=1)\n",
    "mu2 = lazy_varifold_or_dist_batch(a2, n2, c2, a2, n2, c2, sigma=1)\n",
    "mu1_2 = lazy_varifold_or_dist_batch(a2, n2, c2, a1, n1, c1, sigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(mu1 + mu2 - 2*mu1_2).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if args['loss']=='varifold2':\n",
    "    \n",
    "    from pykeops.torch import LazyTensor\n",
    "    # PyKeOps counterpart\n",
    "    KeOpsdeviceId = device.index  # id of Gpu device (in case Gpu is  used)\n",
    "    KeOpsdtype = torchdtype.__str__().split(\".\")[1]  # 'float32'\n",
    "    \n",
    "    #new_faces = torch.Tensor(faces).to(dtype=torch.int32, device=device).repeat(args['batch_size'],1,1)\n",
    "    def loss_varifold(outputs, targets):\n",
    "        \n",
    "        new_faces = torch.Tensor(faces).to(dtype=torch.long, device=device).repeat(outputs.shape[0],1,1)\n",
    "        a1, n1, c1, _ = prepare_batch(outputs, new_faces, centroid=False)\n",
    "        a2, n2, c2, _ = prepare_batch(targets, new_faces, centroid=False)\n",
    "        L = lazy_varifold_or_dist_batch(a1, n1, c1, a1, n1, c1, sigma=1) + lazy_varifold_or_dist_batch(a2, n2, c2, a2, n2, c2, sigma=1) - 2*(lazy_varifold_or_dist_batch(a2, n2, c2, a1, n1, c1, sigma=1))\n",
    "        \n",
    "        return L.sqrt().mean()\n",
    "    loss_fn = loss_varifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "sigma = torch.tensor([sigma], dtype=torchdtype, device=device)\n",
    "if args['loss']=='varifold':\n",
    "    \n",
    "    import lddmm_utils\n",
    "    # PyKeOps counterpart\n",
    "    KeOpsdeviceId = device.index  # id of Gpu device (in case Gpu is  used)\n",
    "    KeOpsdtype = torchdtype.__str__().split(\".\")[1]  # 'float32'\n",
    "    \n",
    "    new_faces = faces.repeat(args['batch_size'],1,1)\n",
    "    def loss_varifold(outputs, targets):\n",
    "        new_faces = faces.repeat(outputs.shape[0],1,1)\n",
    "        V1, F1 = outputs.to(dtype=torchdtype, device=device).requires_grad_(True), new_faces.to(dtype=torch.int32, device=device)\n",
    "        V2, F2 = targets.to(dtype=torchdtype, device=device).requires_grad_(True), new_faces.to(dtype=torch.int32, device=device)\n",
    "        \n",
    "        #L = torch.Tensor([lddmm_utils.lossVarifoldSurf(F1[i], V2[i], F2[i],\n",
    "        #                  lddmm_utils.GaussLinKernel(sigma=sigma))(V1[i]) for i in range(new_faces.shape[0])]).requires_grad_(True).mean()\n",
    "        \n",
    "        L = torch.stack([lddmm_utils.lossVarifoldSurf(F1[i], V2[i], F2[i],\n",
    "                          lddmm_utils.GaussLinKernel(sigma=sigma))(V1[i]) for i in range(new_faces.shape[0])]).requires_grad_(True).sqrt().mean()\n",
    "        \n",
    "        return L\n",
    "    loss_fn = loss_varifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args['loss']=='chamfer':\n",
    "    from chamfer_distance import ChamferDistance as chamfer_dist\n",
    "    def loss_chamfer(outputs, targets):\n",
    "        dist1, dist2, idx1, idx2 = chamfer_dist(outputs,targets)\n",
    "        loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "        return loss\n",
    "    loss_fn = loss_chamfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['loss']=='l1':\n",
    "    def loss_l1(outputs, targets):\n",
    "        #print(outputs)\n",
    "        L = torch.abs(outputs - targets).mean()\n",
    "        return L \n",
    "    loss_fn = loss_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['loss']=='chamfer_varifold':\n",
    "    \n",
    "    import lddmm_utils\n",
    "    from chamfer_distance import ChamferDistance as chamfer_dist\n",
    "    \n",
    "    # PyKeOps counterpart\n",
    "    KeOpsdeviceId = device.index  # id of Gpu device (in case Gpu is  used)\n",
    "    KeOpsdtype = torchdtype.__str__().split(\".\")[1]  # 'float32'\n",
    "    \n",
    "    new_faces = faces.repeat(args['batch_size'],1,1)\n",
    "    def loss_varifold(outputs, targets):\n",
    "        new_faces = faces.repeat(outputs.shape[0],1,1)\n",
    "        V1, F1 = outputs.to(dtype=torchdtype, device=device).requires_grad_(True), new_faces.to(dtype=torch.int32, device=device)\n",
    "        V2, F2 = targets.to(dtype=torchdtype, device=device).requires_grad_(True), new_faces.to(dtype=torch.int32, device=device)\n",
    "        \n",
    "        L = torch.Tensor([lddmm_utils.lossVarifoldSurf(F1[i], V2[i], F2[i],\n",
    "                          lddmm_utils.GaussLinKernel(sigma=sigma))(V1[i]) for i in range(new_faces.shape[0])]).sqrt().mean().requires_grad_(True)\n",
    "        \n",
    "        return L\n",
    "    \n",
    "    def loss_chamfer(outputs, targets):\n",
    "        dist1, dist2, idx1, idx2 = chamfer_dist(outputs,targets)\n",
    "        loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "        return loss\n",
    "    \n",
    "    def loss_chamfer_varifold(outputs, targets):\n",
    "        return(loss_chamfer(outputs, targets)*2 + loss_varifold(outputs,targets)/200)\n",
    "    \n",
    "    loss_fn = loss_chamfer_varifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 2217385\n",
      "PointNetAutoEncoder(\n",
      "  (encoder): Encoder(\n",
      "    (ptnet): SimplePointNet(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (transformers): ModuleList(\n",
      "        (0): SimpleTransformer(\n",
      "          (conv_layers): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (fc_layers): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "              (1): ReLU()\n",
      "            )\n",
      "            (1): Linear(in_features=256, out_features=9, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fc_layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc1): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=128, out_features=15072, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params)) \n",
    "print(model)\n",
    "# print(M[4].v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args['mode'] == 'train':\n",
    "    writer = SummaryWriter(summary_path)\n",
    "    with open(os.path.join(args['results_folder'],'checkpoints', args['name'] +'_params.json'),'w') as fp:\n",
    "        saveparams = copy.deepcopy(args)\n",
    "        json.dump(saveparams, fp)\n",
    "        \n",
    "    if args['resume']:\n",
    "            print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file'])))\n",
    "            checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "            start_epoch = checkpoint_dict['epoch'] + 1\n",
    "            model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "            optim.load_state_dict(checkpoint_dict['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint_dict['scheduler_state_dict'])\n",
    "            print('Resuming from epoch %s'%(str(start_epoch)))     \n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        \n",
    "    if args['generative_model'] == 'autoencoder':\n",
    "        train_autoencoder_dataloader(dataloader_train, dataloader_val,\n",
    "                          device, model, optim, loss_fn,\n",
    "                          bsize = args['batch_size'],\n",
    "                          start_epoch = start_epoch,\n",
    "                          n_epochs = args['num_epochs'],\n",
    "                          eval_freq = args['eval_frequency'],\n",
    "                          scheduler = scheduler,\n",
    "                          writer = writer,\n",
    "                          save_recons=True,\n",
    "                          shapedata=shapedata,\n",
    "                          metadata_dir=checkpoint_path, samples_dir=samples_path,\n",
    "                          checkpoint_path = args['checkpoint_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from file ../Data/COMA/results_identity/pointnet_original_autoencoder/latent_128/checkpoints/checkpoint.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:01<00:00, 49.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder: normalized loss 0.7102287411689758\n",
      "autoencoder: euclidean distance in mm= 3.789044141769409\n"
     ]
    }
   ],
   "source": [
    "args['mode']='test'\n",
    "if args['mode'] == 'test':\n",
    "    print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar')))\n",
    "    checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "    model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "        \n",
    "    targets, predictions, norm_l1_loss, l2_loss = test_autoencoder_dataloader(device, model, dataloader_test, \n",
    "                                                                     shapedata, mm_constant = 1000)    \n",
    "    np.save(os.path.join(prediction_path,'predictions'), predictions)\n",
    "    np.save(os.path.join(prediction_path,'targets'), targets)\n",
    "        \n",
    "    print('autoencoder: normalized loss', norm_l1_loss)\n",
    "    \n",
    "    print('autoencoder: euclidean distance in mm=', l2_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
