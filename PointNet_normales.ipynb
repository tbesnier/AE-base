{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A3000 Laptop GPU'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import mesh_sampling\n",
    "import trimesh\n",
    "from shape_data import ShapeData\n",
    "from SimplePointNet_normales import SimplePointNet, PointNetAutoEncoder, Decoder, Encoder, SimpleTransformer\n",
    "\n",
    "from autoencoder_dataset import autoencoder_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spiral_utils import get_adj_trigs, generate_spirals\n",
    "from models import SpiralAutoencoder\n",
    "from train_funcs_normales import train_autoencoder_dataloader\n",
    "from test_funcs_normales import test_autoencoder_dataloader\n",
    "\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "meshpackage = 'trimesh' # 'mpi-mesh', 'trimesh'\n",
    "root_dir = '../Data'\n",
    "\n",
    "dataset = 'COMA'\n",
    "name = ''\n",
    "\n",
    "GPU = True\n",
    "device_idx = 0\n",
    "torch.cuda.get_device_name(device_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "generative_model = 'autoencoder'\n",
    "downsample_method = 'COMA_downsample' # choose'COMA_downsample' or 'meshlab_downsample'\n",
    "\n",
    "\n",
    "# below are the arguments for the DFAUST run\n",
    "reference_mesh_file = os.path.join(root_dir, dataset, 'template', 'template.obj')\n",
    "downsample_directory = os.path.join(root_dir, dataset,'template', downsample_method)\n",
    "ds_factors = [4, 4, 4, 4]\n",
    "step_sizes = [2, 2, 1, 1, 1]\n",
    "filter_sizes_enc = [[64, 128], 64, [128, 64, 64]]\n",
    "filter_sizes_dec = [256]\n",
    "dilation_flag = True\n",
    "if dilation_flag:\n",
    "    dilation=[2, 2, 1, 1, 1] \n",
    "else:\n",
    "    dilation = None\n",
    "reference_points = [[3567,4051,4597]] #[[414]]  # [[3567,4051,4597]] used for COMA with 3 disconnected components\n",
    "\n",
    "args = {'generative_model': generative_model,\n",
    "        'name': name, 'data': os.path.join(root_dir, dataset, 'preprocessed_identity_pointnet_normales',name),\n",
    "        'results_folder':  os.path.join(root_dir, dataset,'results_identity/pointnet_normales_'+ generative_model),\n",
    "        'reference_mesh_file':reference_mesh_file, 'downsample_directory': downsample_directory,\n",
    "        'checkpoint_file': 'checkpoint',\n",
    "        'seed':2, 'loss':'varifold',\n",
    "        'batch_size':16, 'num_epochs':50, 'eval_frequency':200, 'num_workers': 4,\n",
    "        'filter_sizes_enc': filter_sizes_enc, 'filter_sizes_dec': filter_sizes_dec,\n",
    "        'nz':128, \n",
    "        'ds_factors': ds_factors, 'step_sizes' : step_sizes, 'dilation': dilation,\n",
    "        'lr':1e-3, \n",
    "        'regularization': 5e-5,\n",
    "        'scheduler': True, 'decay_rate': 0.99,'decay_steps':1,  \n",
    "        'resume': False,\n",
    "        'mode':'train', 'shuffle': True, 'nVal': 100, 'normalization': True}\n",
    "\n",
    "args['results_folder'] = os.path.join(args['results_folder'],'latent_'+str(args['nz']))\n",
    "    \n",
    "if not os.path.exists(os.path.join(args['results_folder'])):\n",
    "    os.makedirs(os.path.join(args['results_folder']))\n",
    "\n",
    "summary_path = os.path.join(args['results_folder'],'summaries',args['name'])\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)  \n",
    "    \n",
    "checkpoint_path = os.path.join(args['results_folder'],'checkpoints', args['name'])\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "samples_path = os.path.join(args['results_folder'],'samples', args['name'])\n",
    "if not os.path.exists(samples_path):\n",
    "    os.makedirs(samples_path)\n",
    "    \n",
    "prediction_path = os.path.join(args['results_folder'],'predictions', args['name'])\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.makedirs(prediction_path)\n",
    "\n",
    "if not os.path.exists(downsample_directory):\n",
    "    os.makedirs(downsample_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args['data']+'/mean.npy') or not os.path.exists(args['data']+'/std.npy'):\n",
    "    train_vert = np.load(args['data']+'/train.npy')[:,:,0:3]\n",
    "    test_vert = np.load(args['data']+'/test.npy')[:,:,0:3]\n",
    "    \n",
    "    np.save(os.path.join(args['data'],'train_vert.npy'),train_vert)\n",
    "    del train_vert\n",
    "    np.save(os.path.join(args['data'],'test_vert.npy'),test_vert)\n",
    "    del test_vert\n",
    "    \n",
    "    shapedata_vert = ShapeData(nVal=args['nVal'], \n",
    "                          train_file=args['data']+'/train_vert.npy', \n",
    "                          test_file=args['data']+'/test_vert.npy', \n",
    "                          reference_mesh_file=args['reference_mesh_file'],\n",
    "                          normalization = args['normalization'],\n",
    "                          meshpackage = meshpackage, load_flag = True)\n",
    "    \n",
    "    mean_vert = shapedata_vert.mean\n",
    "    std_vert = shapedata_vert.std\n",
    "    del shapedata_vert\n",
    "    \n",
    "    train_norm = np.load(args['data']+'/train.npy')[:,:,3:]\n",
    "    np.save(os.path.join(args['data'],'train_norm.npy'),train_norm)\n",
    "    del train_norm\n",
    "    \n",
    "    test_norm = np.load(args['data']+'/test.npy')[:,:,3:]\n",
    "    np.save(os.path.join(args['data'],'test_norm.npy'),test_norm)\n",
    "    del test_norm\n",
    "    \n",
    "    shapedata_norm = ShapeData(nVal=args['nVal'], \n",
    "                          train_file=args['data']+'/train_norm.npy', \n",
    "                          test_file=args['data']+'/test_norm.npy', \n",
    "                          reference_mesh_file=args['reference_mesh_file'],\n",
    "                          normalization = args['normalization'],\n",
    "                          meshpackage = meshpackage, load_flag = True)\n",
    "\n",
    "    mean_norm = shapedata_norm.mean\n",
    "    std_norm = shapedata_norm.std\n",
    "    del shapedata_norm\n",
    "    \n",
    "    np.save(args['data']+'/mean.npy', np.hstack((mean_vert, mean_norm)))\n",
    "    np.save(args['data']+'/std.npy', np.hstack((std_vert, std_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data .. \n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args['seed'])\n",
    "print(\"Loading data .. \")\n",
    "if not os.path.exists(args['data']+'/mean.npy') or not os.path.exists(args['data']+'/std.npy'):\n",
    "    shapedata =  ShapeData(nVal=args['nVal'], \n",
    "                          train_file=args['data']+'/train.npy', \n",
    "                          test_file=args['data']+'/test.npy', \n",
    "                          reference_mesh_file=args['reference_mesh_file'],\n",
    "                          normalization = args['normalization'],\n",
    "                          meshpackage = meshpackage, load_flag = True)\n",
    "    np.save(args['data']+'/mean.npy', shapedata.mean)\n",
    "    np.save(args['data']+'/std.npy', shapedata.std)\n",
    "else:\n",
    "    shapedata = ShapeData(nVal=args['nVal'], \n",
    "                         train_file=args['data']+'/train.npy',\n",
    "                         test_file=args['data']+'/test.npy', \n",
    "                         reference_mesh_file=args['reference_mesh_file'],\n",
    "                         normalization = args['normalization'],\n",
    "                         meshpackage = meshpackage, load_flag = False)\n",
    "    shapedata.mean = np.load(args['data']+'/mean.npy')\n",
    "    shapedata.std = np.load(args['data']+'/std.npy')\n",
    "    shapedata.n_vertex = shapedata.mean.shape[0]\n",
    "    shapedata.n_features = shapedata.mean.shape[1]\n",
    "    \n",
    "print(\"... Done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#tspirals = [torch.from_numpy(s).long().to(device) for s in spirals_np]\n",
    "#tD = [torch.from_numpy(s).float().to(device) for s in bD]\n",
    "#tU = [torch.from_numpy(s).float().to(device) for s in bU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# Building model, optimizer, and loss function\n",
    "\n",
    "dataset_train = autoencoder_dataset(root_dir = args['data'], points_dataset = 'train',\n",
    "                                           shapedata = shapedata,\n",
    "                                           normalization = args['normalization'])\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = args['shuffle'], num_workers = args['num_workers'])\n",
    "\n",
    "dataset_val = autoencoder_dataset(root_dir = args['data'], points_dataset = 'val', \n",
    "                                         shapedata = shapedata,\n",
    "                                         normalization = args['normalization'])\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = False, num_workers = args['num_workers'])\n",
    "\n",
    "dataset_test = autoencoder_dataset(root_dir = args['data'], points_dataset = 'test',\n",
    "                                          shapedata = shapedata,\n",
    "                                          normalization = args['normalization'])\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=args['batch_size'],\\\n",
    "                                     shuffle = False, num_workers = args['num_workers'])\n",
    "\n",
    "\n",
    "\n",
    "if 'autoencoder' in args['generative_model']:\n",
    "        model = PointNetAutoEncoder(latent_size=args['nz'],\n",
    "                                    filter_enc = args['filter_sizes_enc'], \n",
    "                                    filter_dec = args['filter_sizes_dec'],  \n",
    "                                    num_points=shapedata.n_vertex+1, \n",
    "                                    device=device).to(device)                  \n",
    "\n",
    "        \n",
    "optim = torch.optim.Adam(model.parameters(),lr=args['lr'],weight_decay=args['regularization'])\n",
    "if args['scheduler']:\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optim, args['decay_steps'],gamma=args['decay_rate'])\n",
    "else:\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mesh = trimesh.load(\"../Data/COMA/template/template.obj\")\n",
    "faces = torch.Tensor(template_mesh.faces)\n",
    "torchdtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.5\n",
    "sigma = torch.tensor([sigma], dtype=torchdtype, device=device)\n",
    "if args['loss']=='varifold':\n",
    "    \n",
    "    import lddmm_utils\n",
    "    # PyKeOps counterpart\n",
    "    KeOpsdeviceId = device.index  # id of Gpu device (in case Gpu is  used)\n",
    "    KeOpsdtype = torchdtype.__str__().split(\".\")[1]  # 'float32'\n",
    "    \n",
    "    new_faces = faces.repeat(args['batch_size'],1,1)\n",
    "    new_faces.shape\n",
    "    def loss_varifold(outputs, targets):\n",
    "        new_faces = faces.repeat(outputs.shape[0],1,1)\n",
    "        V1, F1 = outputs.to(dtype=torchdtype, device=device).requires_grad_(True), new_faces.to(dtype=torch.int32, device=device)\n",
    "        V2, F2 = targets.to(dtype=torchdtype, device=device).requires_grad_(True), new_faces.to(dtype=torch.int32, device=device)\n",
    "        \n",
    "        L = torch.Tensor([lddmm_utils.lossVarifoldSurf(F1[i], V2[i], F2[i],\n",
    "                          lddmm_utils.GaussLinKernel(sigma=sigma))(V1[i]) for i in range(new_faces.shape[0])]).mean().requires_grad_(True)\n",
    "        \n",
    "        return L/250\n",
    "    loss_fn = loss_varifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['loss']=='l1':\n",
    "    def loss_l1(outputs, targets):\n",
    "        L = torch.abs(outputs - targets).mean()\n",
    "        return L \n",
    "    loss_fn = loss_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 4170436\n",
      "PointNetAutoEncoder(\n",
      "  (encoder): Encoder(\n",
      "    (ptnet): SimplePointNet(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv1d(6, 64, kernel_size=(1,), stride=(1,))\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (transformers): ModuleList(\n",
      "        (0): SimpleTransformer(\n",
      "          (conv_layers): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Conv1d(6, 64, kernel_size=(1,), stride=(1,))\n",
      "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "              (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (fc_layers): ModuleList(\n",
      "            (0): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "              (1): ReLU()\n",
      "            )\n",
      "            (1): Linear(in_features=256, out_features=36, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fc_layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc1): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=256, out_features=15072, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params)) \n",
    "print(model)\n",
    "# print(M[4].v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [00:59<00:00, 19.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 14.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | tr 75.48644926134976 | val 69.08047039031982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:00<00:00, 19.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | tr 75.74868025374316 | val 34.475608329772946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:03<00:00, 18.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | tr 75.66641307938919 | val 22.794680976867674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:03<00:00, 18.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | tr 75.11001621947825 | val 39.36597602844238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:02<00:00, 18.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | tr 75.46171915609904 | val 52.79528163909912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:03<00:00, 18.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | tr 75.33819936186984 | val 60.460052757263185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:03<00:00, 18.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 | tr 75.62495897554422 | val 44.31191131591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 | tr 75.74899192336981 | val 46.09252861022949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:08<00:00, 17.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 | tr 75.31404115639083 | val 57.93900695800781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:08<00:00, 17.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 | tr 75.18501401470841 | val 47.00588939666748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:08<00:00, 17.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | tr 75.77023256904607 | val 49.94923915863037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:08<00:00, 17.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | tr 75.9053212167255 | val 29.362185707092284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:08<00:00, 17.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | tr 75.56492968578976 | val 46.24803485870361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 | tr 75.41636421094691 | val 46.721008415222165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 | tr 75.63534165810553 | val 49.53522777557373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 | tr 75.22061754670094 | val 44.84955505371094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 | tr 75.60066195345118 | val 42.32559505462646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 | tr 75.8362555602403 | val 44.899335403442386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 | tr 75.26824959544213 | val 39.49003818511963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:09<00:00, 16.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 | tr 75.34396653385679 | val 38.54644729614258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1174/1174 [01:10<00:00, 16.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 | tr 76.04214997680717 | val 50.611430892944334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                            | 686/1174 [00:41<00:29, 16.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerative_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoencoder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtrain_autoencoder_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                      \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_frequency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                      \u001b[49m\u001b[43msave_recons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mshapedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshapedata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmetadata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/phd/projects/AE-base/train_funcs_normales.py:30\u001b[0m, in \u001b[0;36mtrain_autoencoder_dataloader\u001b[0;34m(dataloader_train, dataloader_val, device, model, optim, loss_fn, bsize, start_epoch, n_epochs, eval_freq, scheduler, writer, save_recons, shapedata, metadata_dir, samples_dir, checkpoint_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m tx_hat \u001b[38;5;241m=\u001b[39m model(tx)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#print(tx_hat.shape, tx.shape)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mloss_varifold\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m     14\u001b[0m V1, F1 \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorchdtype, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m), new_faces\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m V2, F2 \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorchdtype, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m), new_faces\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 17\u001b[0m L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([lddmm_utils\u001b[38;5;241m.\u001b[39mlossVarifoldSurf(F1[i], V2[i], F2[i],\n\u001b[1;32m     18\u001b[0m                   lddmm_utils\u001b[38;5;241m.\u001b[39mGaussLinKernel(sigma\u001b[38;5;241m=\u001b[39msigma))(V1[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new_faces\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m250\u001b[39m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m V1, F1 \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorchdtype, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m), new_faces\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m V2, F2 \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorchdtype, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m), new_faces\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 17\u001b[0m L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[43mlddmm_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlossVarifoldSurf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlddmm_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGaussLinKernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new_faces\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m250\u001b[39m\n",
      "File \u001b[0;32m~/phd/projects/AE-base/lddmm_utils.py:132\u001b[0m, in \u001b[0;36mlossVarifoldSurf.<locals>.loss\u001b[0;34m(VS)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(VS):\n\u001b[1;32m    128\u001b[0m     CS, LS, NSn \u001b[38;5;241m=\u001b[39m get_center_length_normal(FS, VS)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    130\u001b[0m             cst\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;241m+\u001b[39m (LS \u001b[38;5;241m*\u001b[39m K(CS, CS, NSn, NSn, LS))\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m--> 132\u001b[0m             \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (LS \u001b[38;5;241m*\u001b[39m \u001b[43mK\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNSn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNTn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLT\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    133\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/AE-base/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:937\u001b[0m, in \u001b[0;36mGenericLazyTensor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;66;03m# we replace by other\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mother\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;241m0\u001b[39m],)\n\u001b[0;32m--> 937\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AE-base/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:624\u001b[0m, in \u001b[0;36mGenred.__call__\u001b[0;34m(self, backend, device_id, ranges, out, *args)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m nred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2048\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhalf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    621\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize of input array is too large for Arg type reduction with float16 dtype..\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    622\u001b[0m         )\n\u001b[0;32m--> 624\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mGenredAutograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_multVar_highdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m postprocess(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction_op, nout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_arg, dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/AE-base/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:117\u001b[0m, in \u001b[0;36mGenredAutograd.forward\u001b[0;34m(ctx, formula, aliases, backend, dtype, device_id_request, ranges, optional_flags, rec_multVar_highdim, nx, ny, out, *args)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ranges:\n\u001b[1;32m    115\u001b[0m     ranges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(r\u001b[38;5;241m.\u001b[39mcontiguous() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ranges)\n\u001b[0;32m--> 117\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmyconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenred_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mny\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbatchdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# relying on the 'ctx.saved_variables' attribute is necessary  if you want to be able to differentiate the output\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m#  of the backward once again. It helps pytorch to keep track of 'who is who'.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39margs, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/AE-base/lib/python3.10/site-packages/pykeops/common/keops_io/LoadKeOps.py:232\u001b[0m, in \u001b[0;36mLoadKeOps.genred\u001b[0;34m(self, device_args, ranges, nx, ny, nbatchdims, out, *args)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_ptr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mget_pointer(out)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutshape \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_keops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mny\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpykeops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhalf2_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m postprocess_half2\n",
      "File \u001b[0;32m~/anaconda3/envs/AE-base/lib/python3.10/site-packages/pykeops/common/keops_io/LoadKeOps_nvrtc.py:42\u001b[0m, in \u001b[0;36mLoadKeOps_nvrtc_class.call_keops\u001b[0;34m(self, nx, ny)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_keops\u001b[39m(\u001b[38;5;28mself\u001b[39m, nx, ny):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_keops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagHostDevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagZero\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_half\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag1D2D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_chunk_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindsi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindsj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindsp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimsx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimsy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimsp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranges_ptr_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_ptr_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margshapes_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if args['mode'] == 'train':\n",
    "    writer = SummaryWriter(summary_path)\n",
    "    with open(os.path.join(args['results_folder'],'checkpoints', args['name'] +'_params.json'),'w') as fp:\n",
    "        saveparams = copy.deepcopy(args)\n",
    "        json.dump(saveparams, fp)\n",
    "        \n",
    "    if args['resume']:\n",
    "            print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file'])))\n",
    "            checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "            start_epoch = checkpoint_dict['epoch'] + 1\n",
    "            model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "            optim.load_state_dict(checkpoint_dict['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint_dict['scheduler_state_dict'])\n",
    "            print('Resuming from epoch %s'%(str(start_epoch)))     \n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        \n",
    "    if args['generative_model'] == 'autoencoder':\n",
    "        train_autoencoder_dataloader(dataloader_train, dataloader_val,\n",
    "                          device, model, optim, loss_fn,\n",
    "                          bsize = args['batch_size'],\n",
    "                          start_epoch = start_epoch,\n",
    "                          n_epochs = args['num_epochs'],\n",
    "                          eval_freq = args['eval_frequency'],\n",
    "                          scheduler = scheduler,\n",
    "                          writer = writer,\n",
    "                          save_recons=False,\n",
    "                          shapedata=shapedata,\n",
    "                          metadata_dir=checkpoint_path, samples_dir=samples_path,\n",
    "                          checkpoint_path = args['checkpoint_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['mode']='test'\n",
    "if args['mode'] == 'test':\n",
    "    print('loading checkpoint from file %s'%(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar')))\n",
    "    checkpoint_dict = torch.load(os.path.join(checkpoint_path,args['checkpoint_file']+'.pth.tar'),map_location=device)\n",
    "    model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "        \n",
    "    target, predictions, norm_l1_loss, l2_loss = test_autoencoder_dataloader(device, model, dataloader_test, \n",
    "                                                                     shapedata, mm_constant = 1000)    \n",
    "    np.save(os.path.join(prediction_path,'predictions'), predictions)\n",
    "    np.save(os.path.join(prediction_path,'targets'), target)\n",
    "        \n",
    "    print('autoencoder: normalized loss', norm_l1_loss)\n",
    "    \n",
    "    print('autoencoder: euclidean distance in mm=', l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
